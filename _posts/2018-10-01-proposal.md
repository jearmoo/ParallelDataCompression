---
title: "proposal"
bg: snow
color: black
style: left
---

# Parallel Data Compression
{: .text-rich-black}

<span id="forkongithub">
  <a href="{{ site.source_link }}" class="bg-tuscan">
    Fork me on GitHub
  </a>
</span>

<p class="center">
  <span class="fa-stack subtlecircle bg-palm-leaf" style="font-size:100px">
    <i class="fa fa-circle fa-stack-2x text-white"></i>
    <i class="fa fa-pied-piper-alt fa-stack-1x text-palm-leaf"></i>
  </span>
</p>

## Summary

We will explore how various lossless compression algorithms can be parallelized,
compare them, and analyze the the effect of parallelization on compression
ratio. These algorithms include Huffman Coding, Arithmetic Coding, and LZ77. We
will use the OpenMP API and benchmark our code on the Xeon Phi on the Carnegie
Mellon Latedays Cluster.

## Background

*Lossless* compression algorithms attempt to compress data into a smaller
amount of memory such that it is possible to decompress it exactly into the
original input. This contrasts *lossy* compression algorithms which can lose
data.

The algorithms that this project attempts to parallelize are three popular
lossless compression algorithms.

The Huffman Coding and Arithmetic Coding algorithms both use entropy encoding
algorithms. This means that they use less memory to represent characters that
occur more frequently at the expense of using more memory to represent
characters that occur more frequently.

The LZ77 algorithm uses a dictionary encoding algorithm which uses a kind of
table to encode the input.

The performance of our implementation will be measure by both speed and
compression ratio. Compression ratio is $$\frac{\text{size of origin input}}{\text{size of compressed input}}$$


## Challenge

Compression ratio can be sacrificed in order for better parallelization. The
question is where to make those sacrifices. We will need to experiment with
various techniques and determine the tradeoffs in those techniques.

Some parts of the different algorithms are inherently sequential.

## Resources

Shun, Julian, and Fuyao Zhao. "Practical parallel Lempel-Ziv factorization." *Data Compression Conference (DCC), 2013*. IEEE, 20

W. Hu, J. Wen, W. Wu, Y. Han, S. Yang and J. Villasenor, "Highly Scalable Parallel Arithmetic Coding on Multi-Core Processors Using LDPC Codes," in *IEEE Transactions on Communications*, vol. 60, no. 2, pp. 289-294, February 2012.

## Goals/Deliverables

Complete sequential and parallel implementations of Huffman Coding,
Arithmetic Coding, and LZ77.

Speedup graphs and charts showing the effect of parallelization on compression ratio.

**Plan to Achieve:** Speedup the algorithms to around 20x when using 64 processors.

**Hope to Achieve:** Speedup the algorithms by more than 20x when using 64 processors.

## Platform

Language: C++

API: OpenMP

Machine: Xeon Phi on the Latedays Cluster

<!--
ICONS

speedup: fa-tachometer, fa-signal
bigbrain: fa-lightbulb-o

 -->